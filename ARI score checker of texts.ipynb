{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARI score checker of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk import ngrams\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automated Readability Index (ARI) is used to score the reading difficulty of a text, for the purposes of selecting the texts of appropriate difficulty for particular type of language learners.<br>\n",
    "\n",
    "ARI score = 4.71µw + 0.5µs − 21.43 <br>\n",
    "\n",
    "where,<br> \n",
    "µw= average number of letters per word, and µs= the average number of words per sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ari_score(sentences,words1):\n",
    "    words=0\n",
    "    letters=0\n",
    "    cleaned_sentences=[] #senetences after removing punctuation tokens from each sentence \n",
    "    for sentence in sentences:\n",
    "        sentence=[word for word in sentence if re.search('\\w',word)]\n",
    "        cleaned_sentences.append(sentence)\n",
    "    words1=[word for word in words1 if re.search('\\w',word)]\n",
    "\n",
    "    for sentence in cleaned_sentences:\n",
    "        words+=len(sentence)\n",
    "    for word in words1:\n",
    "        letters+=len(word)    \n",
    "    us=words/len(cleaned_sentences) #average number of words in sentence\n",
    "    uw=letters/len(words1) #average number of letters in word\n",
    "    return (4.71*uw + 0.5*us-21.43) #return ARI score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adventure ARI score 5.221487395441105 \n",
      "\n",
      "belles_lettres ARI score 11.603589988900652 \n",
      "\n",
      "editorial ARI score 10.275979124452455 \n",
      "\n",
      "fiction ARI score 5.953167682149875 \n",
      "\n",
      "government ARI score 12.906571734123524 \n",
      "\n",
      "hobbies ARI score 9.842329166489787 \n",
      "\n",
      "humor ARI score 8.747868008413196 \n",
      "\n",
      "learned ARI score 12.663188374782528 \n",
      "\n",
      "lore ARI score 10.93555529093716 \n",
      "\n",
      "mystery ARI score 4.963400602180613 \n",
      "\n",
      "news ARI score 10.953996534497577 \n",
      "\n",
      "religion ARI score 10.8609714154016 \n",
      "\n",
      "reviews ARI score 11.521939165842404 \n",
      "\n",
      "romance ARI score 5.4321607583271 \n",
      "\n",
      "science_fiction ARI score 6.3294322403234275 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in brown.categories():\n",
    "    sentences=brown.sents(categories=i)\n",
    "    words1=brown.words(categories=i)\n",
    "    ari=ari_score(sentences,words1)\n",
    "    print(i , \"ARI score\", ari,\"\\n\") #print ARI score of each category in brown corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Easiest category**: mystery<br>\n",
    "**Most difficult category**: government"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import europarl_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European Parliament Proceedings Parallel Corpus ARI score:  14.17116709989007 \n",
      "\n",
      "News ARI score:  10.953996534497577 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences=europarl_raw.english.sents()\n",
    "words2=europarl_raw.english.words()\n",
    "ari=ari_score(sentences,words2)\n",
    "print(\"European Parliament Proceedings Parallel Corpus ARI score: \", ari,\"\\n\")\n",
    "\n",
    "sentences=sentences=brown.sents(categories=\"news\")\n",
    "words2=brown.words(categories=\"news\")\n",
    "ari=ari_score(sentences,words2)\n",
    "print(\"News ARI score: \", ari,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis: Speeches are easier to understand than news.<br>\n",
    "This hypothesis is false as ARI score of speeches is more than that of news. So, news are easy to understand than speeches.<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
