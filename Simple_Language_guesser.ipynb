{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Language Guesser using Character Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import udhr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The following function  \"build_language_models(languages, language_base)\", is returning conditional frequency distribution of lower case character bigrams with conditions are languages.<br>\n",
    "\n",
    "2. Algorithm explanation:<br>\n",
    "First initialised a blank dictionary to save character bigrams. Using loop, list of words are converted into character bigrams and saved into language_base2. Then, conditional frequency distribution is calculated with dictionary of character bigrams. Return conditional frequency distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_language_models(languages, language_base):\n",
    "    language_base2=dict([(key, []) for key in languages]) #initialised new dict with keys as languages\n",
    "    \n",
    "    for language in languages:\n",
    "        for word in language_base[language]:\n",
    "            language_base2[language].extend(list(nltk.bigrams(word.lower()))) #fill dictionary with character bigrams\n",
    "            \n",
    "    #Now find conditional frequency distribution of character bigrams with keys as languages        \n",
    "    cfd=nltk.ConditionalFreqDist((lang,bi) for lang in language_base2.keys() for bi in language_base2[lang])    \n",
    "    return cfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English ('u', 'n') -> 0.0063174114021571645\n",
      "English ('n', 'i') -> 0.004930662557781202\n",
      "English ('i', 'v') -> 0.0032357473035439137\n",
      "English ('v', 'e') -> 0.01140215716486903\n",
      "English ('e', 'r') -> 0.020338983050847456\n",
      "English ('r', 's') -> 0.003389830508474576\n",
      "English ('s', 'a') -> 0.001694915254237288\n",
      "English ('a', 'l') -> 0.019106317411402157\n",
      "English ('d', 'e') -> 0.00600924499229584\n",
      "English ('e', 'c') -> 0.007087827426810477\n",
      "German_Deutsch ('d', 'i') -> 0.0099361249112846\n",
      "German_Deutsch ('i', 'e') -> 0.016465578424414477\n",
      "German_Deutsch ('a', 'l') -> 0.008232789212207239\n",
      "German_Deutsch ('l', 'l') -> 0.005961674946770759\n",
      "German_Deutsch ('l', 'g') -> 0.00127750177430802\n",
      "German_Deutsch ('g', 'e') -> 0.02185947480482612\n",
      "German_Deutsch ('e', 'm') -> 0.0055358410220014195\n",
      "German_Deutsch ('m', 'e') -> 0.006813342796309439\n",
      "German_Deutsch ('e', 'i') -> 0.02995031937544358\n",
      "German_Deutsch ('i', 'n') -> 0.01973030518097942\n",
      "Finnish_Suomi ('i', 'h') -> 0.0037654653039268424\n",
      "Finnish_Suomi ('h', 'm') -> 0.002555137170521786\n",
      "Finnish_Suomi ('m', 'i') -> 0.011565357719203874\n",
      "Finnish_Suomi ('i', 's') -> 0.03388918773534158\n",
      "Finnish_Suomi ('s', 'o') -> 0.0034965034965034965\n",
      "Finnish_Suomi ('o', 'i') -> 0.013717052178590641\n",
      "Finnish_Suomi ('i', 'k') -> 0.01681011296395912\n",
      "Finnish_Suomi ('k', 'e') -> 0.01277568585260893\n",
      "Finnish_Suomi ('e', 'u') -> 0.008606777837547068\n",
      "Finnish_Suomi ('u', 'k') -> 0.007530930607853685\n",
      "Italian ('d', 'i') -> 0.0317743132887899\n",
      "Italian ('i', 'c') -> 0.009651076466221232\n",
      "Italian ('c', 'h') -> 0.005642167780252413\n",
      "Italian ('h', 'i') -> 0.0014847809948032665\n",
      "Italian ('i', 'a') -> 0.009651076466221232\n",
      "Italian ('a', 'r') -> 0.012472160356347439\n",
      "Italian ('r', 'a') -> 0.009651076466221232\n",
      "Italian ('a', 'z') -> 0.006829992576095026\n",
      "Italian ('z', 'i') -> 0.010987379361544172\n",
      "Italian ('i', 'o') -> 0.015738678544914626\n"
     ]
    }
   ],
   "source": [
    "languages = ['English', 'German_Deutsch', 'Finnish_Suomi', 'Italian']\n",
    "language_base = dict((language, udhr.words(language + '-Latin1')) for language in languages)\n",
    "language_model_cfd = build_language_models(languages, language_base)\n",
    "\n",
    "# print the models for visual inspection\n",
    "for language in languages:\n",
    "    for key in list(language_model_cfd[language].keys())[:10]:\n",
    "        print(language, key, \"->\", language_model_cfd[language].freq(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm: <br>\n",
    "\n",
    "**Input**: language_model_cfd, text\n",
    "<br>\n",
    "**Output**: language_guess\n",
    "<br><br>\n",
    "**Initialize**: test_text_char_bigram= [   ],  score_checker={language:0} where language in language_model_cfd.keys() \n",
    "<br>\n",
    "**begin**:<br>\n",
    "1.**for** word in words **do**<br>\n",
    "2.&emsp;    Convert word into lower case.<br>\n",
    "3.&emsp;    Find character bigram of converted word.<br>\n",
    "4.&emsp;    Append bigram to test_text_char_bigram.<br>\n",
    "5.**for** language in language_model_cfd **do**<br>\n",
    "6.&emsp;    **for** char_bigram in test_text_char_bigram **do**<br>\n",
    "7.&emsp;&emsp;        score_checker[language]+=language_model_cfd[language].freq(char_bigram)<br>\n",
    "8.max_score=max(score_checker.values())<br>\n",
    "9.**for** language in score_checker.values() **do**<br>\n",
    "10.&emsp;    **if** score_checker[language] is max_score **do**<br>\n",
    "11.&emsp;&emsp;        language_guess=language<br>\n",
    "        \n",
    "12.return language_guess<br>        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm explanation:\n",
    "This algorithm is based on finding out overall score of cumulative frequency sum of character bigrams in test text with respect to each language available in conditional frequency distribution. Then it selects language with maximum overall score. This algorithm was able to guess language of all 4 texts given in the problem, correctly. \n",
    "\n",
    "1. In steps 1 to 4, algorithm is constructing a list of character bigrams in text given from its words.\n",
    "2. In steps 5 to 7, algorithm is constructing a dictionary with keys as the names of languages and values are cumulatively added frequency score of each bigram. For, example, suppose bigram ('i','e') is more frequent in German than English. So, obviously it will have a high frequency score in German than English. So, for each bigram in text, we continue adding frequency score and maintain final overall score of each language in a dictionary named score_checker.\n",
    "3. In the steps 9 to 11, algorithm is finding out language with highest overall cumulative score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the following code. It prints dictionary [score_checker] with languages as keys and values as cumulative frequency score using character bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'English': 0.8713405238828973,\n",
       " 'German_Deutsch': 0.8600425833924772,\n",
       " 'Finnish_Suomi': 0.6358257127487892,\n",
       " 'Italian': 1.0007423904974013}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Come in altri paesi europei del mediterraneo, sono presenti tratti distintivi ed elementi che caratterizzano la dieta mediterranea.\"\n",
    "words=text.split(\" \")       #Convert the given text into list of words  \n",
    "test_text_char_bigrams=[]   #This list is used to store character bigrams of the given text\n",
    "\n",
    "for word in words:\n",
    "    #Save lower case charcter bigrams from list of words.\n",
    "    test_text_char_bigrams.extend(list(nltk.bigrams(word.lower())))\n",
    "\n",
    "#Initialize dictionary with keys as languages and value=0\n",
    "score_checker=dict.fromkeys(language_model_cfd.keys(),0)\n",
    "\n",
    "#Save consecutive fequency score of each bigram for each language in language_model_cfd. \n",
    "for language in language_model_cfd.keys():\n",
    "    for char_bigram in test_text_char_bigrams:\n",
    "        score_checker[language]+=language_model_cfd[language].freq(char_bigram)\n",
    "\n",
    "(score_checker)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As evident from  above output, the best guess for given text is **\"Italian\"** as its having highest cumulative frequency score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_language(language_model_cfd, text):\n",
    "    words=text.split(\" \")       #Convert the given text into list of words  \n",
    "    test_text_char_bigrams=[]   #This list is used to store character bigrams of the given text\n",
    "    \n",
    "    for word in words:\n",
    "        #Save lower case charcter bigrams from list of words\n",
    "        test_text_char_bigrams.extend(list(nltk.bigrams(word.lower())))\n",
    "    \n",
    "    #Initialize dictionary with keys as languages and value=0\n",
    "    score_checker=dict.fromkeys(language_model_cfd.keys(),0)\n",
    "    \n",
    "    #Save consecutive fequency score of each bigram for each language in language_model_cfd \n",
    "    for language in language_model_cfd.keys():\n",
    "        for char_bigram in test_text_char_bigrams:\n",
    "            score_checker[language]+=language_model_cfd[language].freq(char_bigram)\n",
    "    max1=max(score_checker.values())  #Find out maximum overall score\n",
    "    \n",
    "    #Find key (language) with maximum overall score as its value\n",
    "    language_guess = [lang for lang in score_checker.keys() if score_checker[lang] is max1]\n",
    "    return language_guess[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Syksy on kaunis vuodenaika, varsinkin kun ei sada.\"\n",
    "text2 = \"Erkenntnisfortschritte ergeben sich durch das Wechselspiel von Beobachtung oder Experiment mit der Theorie.\"\n",
    "text3 = \"Come in altri paesi europei del mediterraneo, sono presenti tratti distintivi ed elementi che caratterizzano la dieta mediterranea.\"\n",
    "text4 = \"A healthy diet is important if you want to live a healthy life.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guess for finnish text is Finnish_Suomi\n",
      "guess for german text is German_Deutsch\n",
      "guess for italian text is Italian\n",
      "guess for english text is English\n"
     ]
    }
   ],
   "source": [
    "print('guess for finnish text is', guess_language(language_model_cfd, text1))\n",
    "print('guess for german text is', guess_language(language_model_cfd, text2))\n",
    "print('guess for italian text is', guess_language(language_model_cfd, text3))\n",
    "print('guess for english text is', guess_language(language_model_cfd, text4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
